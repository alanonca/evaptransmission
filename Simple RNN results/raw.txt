
C:\Users\yzhu2\evaptransmission>python run RH_eqsize.csv
python: can't open file 'run': [Errno 2] No such file or directory

C:\Users\yzhu2\evaptransmission>python runRNN.py
Harris

Creating a 10-70-1 neural network

Setting maxEpochs = 100000.0
Setting learning rate = 0.000100

Starting training
epoch = 2000 ms error = 0.6878
epoch = 4000 ms error = 0.5549
epoch = 6000 ms error = 0.4752
epoch = 8000 ms error = 0.3795
epoch = 10000 ms error = 0.2307
epoch = 12000 ms error = 0.0897
epoch = 14000 ms error = 0.0246
epoch = 16000 ms error = 0.0051
epoch = 18000 ms error = 0.0013
epoch = 20000 ms error = 0.0002
epoch = 22000 ms error = 0.0000
epoch = 24000 ms error = 0.0000
epoch = 26000 ms error = 0.0000
epoch = 28000 ms error = 0.0000
epoch = 30000 ms error = 0.0000
epoch = 32000 ms error = 0.0000
epoch = 34000 ms error = 0.0000
epoch = 36000 ms error = 0.0000
epoch = 38000 ms error = 0.0000
epoch = 40000 ms error = 0.0000
epoch = 42000 ms error = 0.0000
epoch = 44000 ms error = 0.0000
epoch = 46000 ms error = 0.0000
epoch = 48000 ms error = 0.0000
epoch = 50000 ms error = 0.0000
epoch = 52000 ms error = 0.0000
epoch = 54000 ms error = 0.0000
epoch = 56000 ms error = 0.0000
epoch = 58000 ms error = 0.0000
epoch = 60000 ms error = 0.0000
epoch = 62000 ms error = 0.0000
epoch = 64000 ms error = 0.0000
epoch = 66000 ms error = 0.0000
epoch = 68000 ms error = 0.0000
epoch = 70000 ms error = 0.0000
epoch = 72000 ms error = 0.0000
epoch = 74000 ms error = 0.0000
epoch = 76000 ms error = 0.0000
epoch = 78000 ms error = 0.0000
epoch = 80000 ms error = 0.0000
epoch = 82000 ms error = 0.0000
epoch = 84000 ms error = 0.0000
epoch = 86000 ms error = 0.0000
epoch = 88000 ms error = 0.0000
epoch = 90000 ms error = 0.0000
epoch = 92000 ms error = 0.0000
epoch = 94000 ms error = 0.0000
epoch = 96000 ms error = 0.0000
epoch = 98000 ms error = 0.0000
epoch = 100000 ms error = 0.0000
Training complete

First few data points: actual-predicted:
0: 8.97, 8.970015
1: 6.62, 6.6199946
2: 6.0, 5.999998
3: 3.27, 3.2700837
4: 5.59, 5.5899677
5: 4.49, 4.490016

Accuracy on data (using train data only) = 1.0000


Check fitting and make predictions
8.970015
6.619995
5.999998
3.270084
5.589968
4.490016
6.000011
6.610003
6.409991
8.190000
6.819996
10.299981
10.099997
9.949994
10.699986
9.359953
6.009921
5.160003
4.489991
6.609993
4.062536
5.035492
4.672750
6.978169
Fitting check complete. Last 4 elements are predictions.

Contour data output
6.430057
6.684758
6.879210
7.034775
7.165445
7.279655
7.389690
7.482614
7.568156
7.647253
7.720592
7.788758
7.852265
7.916006
7.971344
8.023381
8.072478
8.118951
8.163083
8.205108
6.314971
6.588875
6.787127
6.937108
7.058075
7.162060
7.262722
7.349220
7.430531
7.507268
7.579702
7.648019
7.712413
7.777638
7.834658
7.888544
7.939572
7.988005
8.034092
8.078052
6.190716
6.500633
6.714603
6.865074
6.977459
7.069112
7.156386
7.232367
7.305677
7.376874
7.445858
7.512355
7.576135
7.641635
7.699496
7.754581
7.807031
7.857020
7.904733
7.950349
6.039682
6.404488
6.651239
6.814222
6.924134
7.004549
7.075997
7.137582
7.198676
7.260443
7.322693
7.384741
7.445862
7.509978
7.567515
7.622917
7.676109
7.727115
7.776022
7.822941
5.840782
6.278970
6.579244
6.772892
6.892851
6.968168
7.024499
7.068853
7.113332
7.160965
7.212176
7.266162
7.321745
7.382107
7.437682
7.492157
7.545158
7.596466
7.646012
7.693788
5.593366
6.113553
6.483402
6.726621
6.873873
6.956593
7.004780
7.033178
7.058998
7.088769
7.124746
7.166728
7.213401
7.267088
7.318594
7.370526
7.422081
7.472729
7.522147
7.570172
5.291026
5.895085
6.345706
6.655925
6.849899
6.957301
7.010340
7.028729
7.036818
7.046328
7.063015
7.088518
7.122113
7.165347
7.209984
7.257199
7.305649
7.354367
7.402692
7.450205
4.938626
5.620311
6.155089
6.544212
6.802451
6.953851
7.030107
7.050371
7.046748
7.036979
7.031989
7.036925
7.052918
7.081164
7.115388
7.155036
7.198168
7.243265
7.289208
7.335225
4.536188
5.284367
5.900711
6.375380
6.712187
6.926761
7.048100
7.087749
7.084526
7.061399
7.035354
7.016804
7.010522
7.018314
7.037467
7.065623
7.100302
7.139354
7.181074
7.224203
4.115711
4.912411
5.597409
6.152698
6.571706
6.860539
7.044775
7.122416
7.136556
7.112577
7.072360
7.032148
7.001832
6.985176
6.984952
6.997537
7.020256
7.050424
7.085707
7.124255
3.680829
4.509006
5.247714
5.874557
6.374318
6.743465
7.004183
7.136954
7.187011
7.178850
7.136604
7.081212
7.028258
6.984714
6.960966
6.953341
6.959752
6.977327
7.003185
7.034830
3.242864
4.086833
4.862699
5.547692
6.120914
6.570157
6.914604
7.115170
7.217892
7.243787
7.216051
7.157653
7.088688
7.019732
6.970162
6.938199
6.923650
6.924242
6.936919
6.958638
2.800386
3.647133
4.444506
5.172839
5.809138
6.334522
6.765807
7.043201
7.212665
7.290323
7.295993
7.251556
7.178909
7.091310
7.016711
6.957561
6.917299
6.895654
6.890239
6.897854
2.380981
3.220730
4.025103
4.779723
5.462980
6.052526
6.564152
6.918414
7.160213
7.300479
7.354717
7.341642
7.281924
7.189392
7.097064
7.012958
6.945517
6.898079
6.870275
6.859599
1.978028
2.804440
3.604964
4.371504
5.086424
5.727102
6.310250
6.738696
7.055120
7.264939
7.379211
7.412737
7.383097
7.302970
7.205022
7.102813
7.009967
6.934815
6.880632
6.846992
1.593637
2.403153
3.192124
3.958683
4.690740
5.368125
6.010615
6.506791
6.896139
7.178103
7.359156
7.450264
7.465430
7.415771
7.328105
7.219984
7.108773
7.007876
6.925523
6.864985
1.228503
2.019722
2.792349
3.549916
4.286487
4.986277
5.673899
6.228236
6.685416
7.038596
7.289173
7.444336
7.514766
7.511003
7.450079
7.351830
7.234540
7.115116
7.006762
6.917663
0.857753
1.629491
2.382011
3.123181
3.853424
4.562876
5.282502
5.886101
6.407074
6.832258
7.156990
7.383914
7.520386
7.577829
7.560976
7.491169
7.384812
7.259403
7.131539
7.014577
0.538784
1.293890
2.027689
2.750502
3.467679
4.175107
4.909890
5.545396
6.113900
6.597836
6.986970
7.279113
7.478247
7.597505
7.630224
7.599495
7.518734
7.403464
7.270534
7.136086
0.235900
0.975854
1.691717
2.394907
3.094521
3.791921
4.530216
5.185554
5.790263
6.324306
6.772671
7.127931
7.389977
7.573708
7.661149
7.678004
7.634894
7.544344
7.421097
7.281367
Contour fitting complete.

End model

King

Creating a 10-70-1 neural network

Setting maxEpochs = 100000.0
Setting learning rate = 0.000100

Starting training
epoch = 2000 ms error = 0.5622
epoch = 4000 ms error = 0.0250
epoch = 6000 ms error = 0.0010
epoch = 8000 ms error = 0.0000
epoch = 10000 ms error = 0.0000
epoch = 12000 ms error = 0.0000
epoch = 14000 ms error = 0.0000
epoch = 16000 ms error = 0.0000
epoch = 18000 ms error = 0.0000
epoch = 20000 ms error = 0.0000
epoch = 22000 ms error = 0.0000
epoch = 24000 ms error = 0.0000
epoch = 26000 ms error = 0.0000
epoch = 28000 ms error = 0.0000
epoch = 30000 ms error = 0.0000
epoch = 32000 ms error = 0.0000
epoch = 34000 ms error = 0.0000
epoch = 36000 ms error = 0.0000
epoch = 38000 ms error = 0.0000
epoch = 40000 ms error = 0.0000
epoch = 42000 ms error = 0.0000
epoch = 44000 ms error = 0.0000
epoch = 46000 ms error = 0.0000
epoch = 48000 ms error = 0.0000
epoch = 50000 ms error = 0.0000
epoch = 52000 ms error = 0.0000
epoch = 54000 ms error = 0.0000
epoch = 56000 ms error = 0.0000
epoch = 58000 ms error = 0.0000
epoch = 60000 ms error = 0.0000
epoch = 62000 ms error = 0.0000
epoch = 64000 ms error = 0.0000
epoch = 66000 ms error = 0.0000
epoch = 68000 ms error = 0.0000
epoch = 70000 ms error = 0.0000
epoch = 72000 ms error = 0.0000
epoch = 74000 ms error = 0.0000
epoch = 76000 ms error = 0.0000
epoch = 78000 ms error = 0.0000
epoch = 80000 ms error = 0.0000
epoch = 82000 ms error = 0.0000
epoch = 84000 ms error = 0.0000
epoch = 86000 ms error = 0.0000
epoch = 88000 ms error = 0.0000
epoch = 90000 ms error = 0.0000
epoch = 92000 ms error = 0.0000
epoch = 94000 ms error = 0.0000
epoch = 96000 ms error = 0.0000
epoch = 98000 ms error = 0.0000
epoch = 100000 ms error = 0.0000
Training complete

First few data points: actual-predicted:
0: 8.04, 8.040001
1: 8.24, 8.240004
2: 8.43, 8.43
3: 9.4, 9.400001
4: 9.39, 9.39
5: 10.8, 10.799997

Accuracy on data (using train data only) = 1.0000


Check fitting and make predictions
8.040001
8.240004
8.430000
9.400001
9.390000
10.799997
9.009999
10.200000
11.700000
8.410000
10.200000
13.899999
15.000000
10.199999
9.369999
13.600000
13.199999
6.230000
8.790000
8.410000
9.137161
12.002422
11.347934
11.132872
Fitting check complete. Last 4 elements are predictions.

Contour data output
7.224126
7.077841
7.199077
7.316520
7.394858
7.436054
7.451879
7.451490
7.440857
7.423965
7.403692
7.382781
7.360874
7.339581
7.320138
7.301323
7.284050
7.268351
7.254693
7.241954
8.391365
7.618539
7.393476
7.419675
7.465554
7.489776
7.494652
7.487080
7.471230
7.450564
7.427394
7.404196
7.380233
7.357107
7.336044
7.315678
7.296968
7.279943
7.265109
7.251248
9.451482
8.750625
7.887309
7.616909
7.575381
7.566661
7.552806
7.533252
7.508883
7.482320
7.454906
7.428594
7.402020
7.376685
7.353751
7.331627
7.311317
7.292826
7.276692
7.261600
10.011033
9.898491
8.964486
8.083619
7.767606
7.680223
7.633436
7.594699
7.556920
7.521228
7.487494
7.456790
7.426760
7.398666
7.373499
7.349361
7.327247
7.307122
7.289557
7.273103
10.218913
10.577383
10.173110
9.116575
8.191318
7.866560
7.748594
7.678228
7.619829
7.570261
7.527071
7.490018
7.455228
7.423554
7.395640
7.369110
7.344936
7.322982
7.303824
7.285872
10.219263
10.895780
10.953253
10.352647
9.149166
8.251414
7.928605
7.795024
7.704063
7.633726
7.576484
7.530138
7.488606
7.452096
7.420657
7.391215
7.364618
7.340577
7.319642
7.300024
10.103478
10.985571
11.374359
11.197297
10.404571
9.129960
8.278904
7.971991
7.819803
7.717758
7.639863
7.579924
7.528677
7.485418
7.449282
7.416141
7.386612
7.360138
7.337178
7.315706
9.919435
10.943888
11.549638
11.696543
11.315534
10.385970
9.077807
8.302087
7.989977
7.831721
7.723059
7.643391
7.578094
7.525226
7.482608
7.444589
7.411374
7.381970
7.356661
7.333082
9.694245
10.829536
11.576725
11.940182
11.887494
11.335419
10.297062
9.029728
8.284788
7.991864
7.832519
7.724577
7.639483
7.573116
7.521541
7.476987
7.439048
7.406062
7.377995
7.352025
9.431089
10.665668
11.521030
12.025517
12.215304
11.985478
11.308255
10.244356
8.947161
8.266644
7.988824
7.834458
7.720337
7.634398
7.569870
7.516025
7.471588
7.433885
7.402344
7.373483
9.139637
10.466834
11.414690
12.018295
12.360335
12.387193
12.008214
11.275166
10.120599
8.861256
8.243080
7.987209
7.827428
7.713486
7.630534
7.563513
7.510035
7.465987
7.429974
7.397546
8.823587
10.239489
11.273382
11.957902
12.399837
12.590266
12.478150
12.000870
11.182760
9.982032
8.776368
8.229395
7.974450
7.817688
7.708565
7.622874
7.556625
7.503799
7.461801
7.424804
8.473519
9.977997
11.098183
11.859059
12.379666
12.673659
12.745191
12.534846
11.954558
11.103567
9.877744
8.750046
8.210805
7.965119
7.815094
7.701925
7.616887
7.551204
7.500625
7.457302
8.102273
9.692053
10.897355
11.732337
12.322000
12.688123
12.866511
12.845728
12.534017
11.883310
11.014563
9.819715
8.691830
8.190485
7.960732
7.806351
7.694536
7.610500
7.547741
7.495638
7.778288
9.436293
10.711905
11.608545
12.253500
12.669823
12.906600
12.980112
12.851042
12.406906
11.679831
10.797271
9.503442
8.533473
8.135390
7.921137
7.777668
7.672564
7.595780
7.533627
7.373846
9.109639
10.468693
11.439924
12.151217
12.623688
12.914477
13.057280
13.063033
12.857291
12.335755
11.616429
10.695786
9.397878
8.509400
8.115839
7.908756
7.768104
7.668105
7.589256
6.954415
8.762766
10.203696
11.250292
12.029209
12.557206
12.895270
13.085299
13.165410
13.109968
12.833067
12.272618
11.521526
10.591305
9.340332
8.464591
8.096239
7.896007
7.762675
7.660177
6.522331
8.397147
9.917648
11.040112
11.888437
12.473228
12.857033
13.085820
13.212272
13.237290
13.128513
12.802071
12.172549
11.427925
10.528344
9.239347
8.422418
8.076851
7.889003
7.752719
6.080012
8.014414
9.611314
10.809638
11.729177
12.372858
12.803222
13.068264
13.229805
13.300858
13.281787
13.133410
12.734324
12.066333
11.365336
10.420737
9.142904
8.382871
8.066502
7.875981
5.705394
7.683698
9.341190
10.602246
11.582319
12.276907
12.747516
13.042834
13.230494
13.328478
13.351048
13.287405
13.062091
12.560400
11.884121
11.164010
10.117613
8.900078
8.297998
8.014174
Contour fitting complete.

End model

LA

Creating a 10-70-1 neural network

Setting maxEpochs = 100000.0
Setting learning rate = 0.000100

Starting training
epoch = 2000 ms error = 1.6551
epoch = 4000 ms error = 1.3003
epoch = 6000 ms error = 1.2335
epoch = 8000 ms error = 0.6655
epoch = 10000 ms error = 0.2488
epoch = 12000 ms error = 0.1290
epoch = 14000 ms error = 0.0656
epoch = 16000 ms error = 0.0237
epoch = 18000 ms error = 0.0112
epoch = 20000 ms error = 0.0070
epoch = 22000 ms error = 0.0060
epoch = 24000 ms error = 0.0021
epoch = 26000 ms error = 0.0013
epoch = 28000 ms error = 0.0009
epoch = 30000 ms error = 0.0008
epoch = 32000 ms error = 0.0008
epoch = 34000 ms error = 0.0005
epoch = 36000 ms error = 0.0003
epoch = 38000 ms error = 0.0003
epoch = 40000 ms error = 0.0003
epoch = 42000 ms error = 0.0003
epoch = 44000 ms error = 0.0004
epoch = 46000 ms error = 0.0003
epoch = 48000 ms error = 0.0009
epoch = 50000 ms error = 0.0002
epoch = 52000 ms error = 0.0003
epoch = 54000 ms error = 0.0002
epoch = 56000 ms error = 0.0002
epoch = 58000 ms error = 0.0002
epoch = 60000 ms error = 0.0002
epoch = 62000 ms error = 0.0001
epoch = 64000 ms error = 0.0001
epoch = 66000 ms error = 0.0001
epoch = 68000 ms error = 0.0004
epoch = 70000 ms error = 0.0001
epoch = 72000 ms error = 0.0001
epoch = 74000 ms error = 0.0001
epoch = 76000 ms error = 0.0001
epoch = 78000 ms error = 0.0001
epoch = 80000 ms error = 0.0002
epoch = 82000 ms error = 0.0001
epoch = 84000 ms error = 0.0001
epoch = 86000 ms error = 0.0001
epoch = 88000 ms error = 0.0001
epoch = 90000 ms error = 0.0001
epoch = 92000 ms error = 0.0004
epoch = 94000 ms error = 0.0001
epoch = 96000 ms error = 0.0001
epoch = 98000 ms error = 0.0001
epoch = 100000 ms error = 0.0001
Training complete

First few data points: actual-predicted:
0: 8.97, 8.968637
1: 10.1, 10.0991745
2: 9.94, 9.942033
3: 9.55, 9.520778
4: 8.98, 8.982295
5: 7.82, 7.820622

Accuracy on data (using train data only) = 0.9000


Check fitting and make predictions
8.968637
10.099174
9.942033
9.520778
8.982295
7.820622
8.209399
9.370910
6.840646
9.180643
9.170645
7.622637
8.007505
7.810430
14.699447
9.932567
9.548299
9.578979
9.935877
9.169314
11.245614
11.505579
10.937815
14.431946
Fitting check complete. Last 4 elements are predictions.

Contour data output
11.523099
10.174324
8.195329
5.454268
4.223045
3.808030
3.500892
3.108314
2.660422
2.192520
1.824749
1.569023
1.406236
1.318397
1.268958
1.244085
1.230994
1.223940
1.220472
1.218612
12.225765
10.832375
9.452996
7.086230
4.797887
4.043283
3.757163
3.460046
3.089485
2.625302
2.180918
1.816650
1.555343
1.403326
1.314058
1.268095
1.243620
1.230353
1.223810
1.220298
12.932728
11.469606
10.208225
8.709003
6.045349
4.384154
3.956712
3.716959
3.446823
3.065324
2.622755
2.180036
1.803098
1.555292
1.398400
1.314036
1.268074
1.242853
1.230339
1.223602
13.539186
12.129847
10.770798
9.654667
7.757855
5.116100
4.172409
3.891240
3.692367
3.416848
3.051584
2.610485
2.152201
1.796023
1.542523
1.395851
1.312621
1.265909
1.242455
1.229752
14.028978
12.822037
11.344401
10.252396
9.066575
6.598939
4.610536
4.046659
3.859273
3.669664
3.410729
3.049071
2.590110
2.152428
1.783435
1.542808
1.396021
1.310099
1.265950
1.241755
14.384948
13.439061
11.958416
10.746202
9.773209
8.215938
5.616108
4.281215
3.980791
3.828871
3.655830
3.399350
3.020025
2.579336
2.125829
1.776971
1.538719
1.388972
1.308815
1.263916
14.650002
13.940373
12.614998
11.258675
10.258392
9.226831
7.242034
4.842644
4.125387
3.935676
3.812383
3.644838
3.375872
3.009632
2.549324
2.117104
1.770692
1.526801
1.386719
1.305096
14.856791
14.327551
13.262365
11.846876
10.714252
9.803430
8.643926
6.124557
4.447684
4.034968
3.913546
3.803207
3.631702
3.374333
2.991618
2.550143
2.118082
1.758937
1.527310
1.382511
15.032351
14.637285
13.853663
12.559280
11.248105
10.275879
9.449935
7.926170
5.408418
4.232350
3.997854
3.906161
3.802719
3.647711
3.389358
3.031289
2.594356
2.140043
1.787663
1.537423
15.154102
14.839861
14.244143
13.173253
11.778401
10.672423
9.875673
8.933189
6.924091
4.696970
4.099857
3.966463
3.889454
3.792805
3.627900
3.374496
3.012472
2.554311
2.122098
1.761927
15.253966
15.000211
14.538007
13.707622
12.374118
11.096076
10.244123
9.469772
8.308959
5.781683
4.342093
4.030449
3.944520
3.879730
3.778893
3.617202
3.359816
2.975657
2.534076
2.087314
15.336199
15.129984
14.762274
14.129685
12.988849
11.577188
10.610988
9.842672
9.078281
7.348360
4.990628
4.156555
3.989523
3.932347
3.868876
3.771145
3.606838
3.331311
2.956784
2.494404
15.403906
15.236348
14.938375
14.449204
13.547831
12.132843
11.000711
10.182689
9.505389
8.530580
6.317218
4.500808
4.054996
3.969166
3.921787
3.862620
3.763956
3.587329
3.316493
2.919431
15.459535
15.323974
15.080203
14.692150
14.002192
12.737597
11.442105
10.522803
9.837618
9.138495
7.819662
5.383192
4.216447
4.009462
3.955095
3.915633
3.857230
3.751405
3.577047
3.287086
15.505102
15.396164
15.196261
14.881817
14.349756
13.321542
11.960265
10.878384
10.155861
9.498992
8.742839
6.877890
4.677239
4.091870
3.982852
3.947301
3.910835
3.849068
3.744668
3.556862
15.550502
15.468584
15.313099
15.067389
14.669437
13.925298
12.696391
11.385143
10.555344
9.878990
9.287777
8.418305
6.140845
4.435441
4.042113
3.975125
3.947545
3.914657
3.862024
3.763641
15.579306
15.514797
15.388311
15.185826
14.862483
14.287824
13.278562
11.876283
10.889870
10.179318
9.583940
8.993971
7.643929
5.251300
4.182187
4.004195
3.965881
3.942368
3.911468
3.855071
15.602719
15.552487
15.450199
15.283610
15.017583
14.563377
13.779093
12.444186
11.266573
10.478686
9.868998
9.317327
8.588726
6.702057
4.598695
4.073335
3.984411
3.959310
3.939336
3.906938
15.621732
15.583119
15.500929
15.364419
15.144554
14.776928
14.172626
13.035408
11.718407
10.784884
10.155149
9.587582
9.038467
8.040663
5.621016
4.281288
4.019813
3.972629
3.955610
3.935930
15.637158
15.607944
15.542340
15.431050
15.249460
14.947235
14.472479
13.572528
12.256776
11.122614
10.437183
9.860056
9.315158
8.747026
7.137679
4.881734
4.120447
3.991136
3.966665
3.952369
Contour fitting complete.

End model

Maricopa

Creating a 10-70-1 neural network

Setting maxEpochs = 100000.0
Setting learning rate = 0.000100

Starting training
epoch = 2000 ms error = 1.6274
epoch = 4000 ms error = 0.7262
epoch = 6000 ms error = 0.5110
epoch = 8000 ms error = 0.3257
epoch = 10000 ms error = 0.2150
epoch = 12000 ms error = 0.1782
epoch = 14000 ms error = 0.1582
epoch = 16000 ms error = 0.1486
epoch = 18000 ms error = 0.1297
epoch = 20000 ms error = 0.0880
epoch = 22000 ms error = 0.0843
epoch = 24000 ms error = 0.0900
epoch = 26000 ms error = 0.0571
epoch = 28000 ms error = 0.0579
epoch = 30000 ms error = 0.0511
epoch = 32000 ms error = 0.0572
epoch = 34000 ms error = 0.0401
epoch = 36000 ms error = 0.0802
epoch = 38000 ms error = 0.0387
epoch = 40000 ms error = 0.0612
epoch = 42000 ms error = 0.0233
epoch = 44000 ms error = 0.0219
epoch = 46000 ms error = 0.0232
epoch = 48000 ms error = 0.0105
epoch = 50000 ms error = 0.0062
epoch = 52000 ms error = 0.0067
epoch = 54000 ms error = 0.0222
epoch = 56000 ms error = 0.0134
epoch = 58000 ms error = 0.0124
epoch = 60000 ms error = 0.0054
epoch = 62000 ms error = 0.0026
epoch = 64000 ms error = 0.0032
epoch = 66000 ms error = 0.0018
epoch = 68000 ms error = 0.0011
epoch = 70000 ms error = 0.0008
epoch = 72000 ms error = 0.0003
epoch = 74000 ms error = 0.0001
epoch = 76000 ms error = 0.0000
epoch = 78000 ms error = 0.0003
epoch = 80000 ms error = 0.0000
epoch = 82000 ms error = 0.0000
epoch = 84000 ms error = 0.0000
epoch = 86000 ms error = 0.0000
epoch = 88000 ms error = 0.0000
epoch = 90000 ms error = 0.0000
epoch = 92000 ms error = 0.0000
epoch = 94000 ms error = 0.0000
epoch = 96000 ms error = 0.0000
epoch = 98000 ms error = 0.0000
epoch = 100000 ms error = 0.0000
Training complete

First few data points: actual-predicted:
0: 15.7, 15.700199
1: 16.7, 16.700169
2: 16.7, 16.700119
3: 17.0, 17.00011
4: 18.1, 18.100008
5: 18.7, 18.7

Accuracy on data (using train data only) = 1.0000


Check fitting and make predictions
15.700199
16.700169
16.700119
17.000111
18.100008
18.700001
17.000072
14.500020
14.500011
15.900033
13.200031
12.300009
13.200209
17.300161
20.100092
19.800110
19.700035
17.800142
16.700172
18.100039
16.827593
15.377699
14.058231
15.281167
Fitting check complete. Last 4 elements are predictions.

Contour data output
17.393030
17.955103
18.239525
18.324629
18.217491
18.006098
17.777191
17.558002
17.381517
17.222307
17.063019
16.923193
16.789942
16.662859
16.532761
16.418140
16.309359
16.198523
16.101219
16.009014
16.215584
17.204178
17.895441
18.270702
18.440020
18.405745
18.223610
17.964865
17.738869
17.543930
17.360563
17.205799
17.060852
16.923464
16.782906
16.658884
16.540956
16.420612
16.314871
16.214703
14.899584
15.919517
16.963150
17.781893
18.287899
18.513607
18.559347
18.416529
18.179003
17.930973
17.697962
17.513380
17.349218
17.198063
17.045425
16.911295
16.783743
16.653376
16.538620
16.429766
14.052914
14.884184
15.891973
16.943501
17.844419
18.331518
18.579157
18.650509
18.534981
18.301779
18.024261
17.796467
17.602684
17.432775
17.266579
17.122759
16.986761
16.847933
16.725647
16.609484
13.292472
13.880034
14.640905
15.591471
16.732258
17.665422
18.274385
18.615400
18.750069
18.711361
18.498287
18.231779
17.978537
17.762943
17.565578
17.403154
17.253536
17.102640
16.970259
16.844528
12.773886
13.189973
13.724599
14.418208
15.377585
16.422512
17.432653
18.212954
18.606680
18.807953
18.845421
18.702806
18.448095
18.173855
17.915676
17.715378
17.541651
17.373270
17.228481
17.092087
12.475131
12.798051
13.204927
13.727374
14.464753
15.345704
16.381863
17.476282
18.220999
18.640232
18.871384
18.927656
18.811991
18.566622
18.263121
18.011572
17.800919
17.607685
17.447998
17.300655
12.198103
12.441741
12.739348
13.112519
13.631147
14.260454
15.071230
16.143024
17.193790
18.057981
18.615528
18.884806
19.011065
18.975355
18.759140
18.474506
18.196947
17.944902
17.750074
17.580233
11.992009
12.185054
12.411040
12.686003
13.059072
13.503464
14.076499
14.883110
15.826828
16.881779
17.904100
18.531588
18.870480
19.054712
19.094213
18.955784
18.692430
18.374979
18.114792
17.898794
11.859715
12.027256
12.214844
12.435793
12.728665
13.071343
13.506622
14.116297
14.855444
15.782648
16.913761
17.875813
18.536369
18.896164
19.106907
19.164942
19.056057
18.784452
18.483353
18.209578
11.718613
11.868192
12.025185
12.200337
12.423381
12.677387
12.993608
13.428057
13.949456
14.623526
15.556890
16.584343
17.606449
18.392206
18.871393
19.110508
19.233093
19.195997
18.994102
18.698393
11.591617
11.734530
11.875481
12.022881
12.200337
12.394646
12.630585
12.948478
13.322927
13.799762
14.468132
15.272746
16.253839
17.301447
18.252512
18.797871
19.091011
19.272594
19.309156
19.180763
11.493836
11.637034
11.772854
11.907910
12.062040
12.223636
12.414316
12.666372
12.959117
13.326832
13.834885
14.447240
15.234310
16.200432
17.325960
18.223936
18.800886
19.127920
19.306749
19.369541
11.371503
11.519487
11.655582
11.784362
11.921962
12.057028
12.208529
12.401868
12.621535
12.893217
13.262390
13.699209
14.257920
14.977613
15.958229
16.996977
17.973724
18.715904
19.085323
19.301508
11.246119
11.401626
11.542690
11.672309
11.803921
11.924885
12.052182
12.206285
12.375428
12.580432
12.854936
13.174999
13.577082
14.087948
14.802222
15.653060
16.660137
17.755949
18.552727
19.020952
11.142643
11.305063
11.451949
11.585456
11.717630
11.834105
11.950505
12.084179
12.225045
12.391559
12.611138
12.864523
13.179623
13.574439
14.118391
14.772516
15.605572
16.680355
17.701548
18.525717
11.009015
11.180429
11.335600
11.476139
11.613257
11.730161
11.841058
11.960089
12.077636
12.210153
12.379629
12.571809
12.808162
13.100970
13.497564
13.965102
14.561934
15.393321
16.346666
17.380482
10.870824
11.051140
11.214920
11.363502
11.508092
11.629721
11.741583
11.855357
11.960351
12.071464
12.206703
12.355502
12.535597
12.756495
13.052732
13.396820
13.827161
14.420403
15.133037
16.025488
10.757407
10.944472
11.115090
11.270261
11.421548
11.548601
11.664211
11.778687
11.879705
11.981069
12.098168
12.222201
12.369101
12.547204
12.784336
13.057935
13.396634
13.855556
14.399144
15.095352
10.613034
10.807499
10.986357
11.149685
11.309464
11.444051
11.566320
11.685629
11.787253
11.883728
11.987667
12.090921
12.207932
12.346198
12.527795
12.735693
12.991273
13.333488
13.730565
14.228870
Contour fitting complete.

End model

SantaClara

Creating a 10-70-1 neural network

Setting maxEpochs = 100000.0
Setting learning rate = 0.000100

Starting training
epoch = 2000 ms error = 0.7124
epoch = 4000 ms error = 0.4056
epoch = 6000 ms error = 0.1164
epoch = 8000 ms error = 0.0439
epoch = 10000 ms error = 0.0203
epoch = 12000 ms error = 0.0075
epoch = 14000 ms error = 0.0029
epoch = 16000 ms error = 0.0011
epoch = 18000 ms error = 0.0011
epoch = 20000 ms error = 0.0002
epoch = 22000 ms error = 0.0001
epoch = 24000 ms error = 0.0001
epoch = 26000 ms error = 0.0000
epoch = 28000 ms error = 0.0000
epoch = 30000 ms error = 0.0000
epoch = 32000 ms error = 0.0000
epoch = 34000 ms error = 0.0000
epoch = 36000 ms error = 0.0000
epoch = 38000 ms error = 0.0000
epoch = 40000 ms error = 0.0000
epoch = 42000 ms error = 0.0000
epoch = 44000 ms error = 0.0000
epoch = 46000 ms error = 0.0000
epoch = 48000 ms error = 0.0000
epoch = 50000 ms error = 0.0000
epoch = 52000 ms error = 0.0000
epoch = 54000 ms error = 0.0000
epoch = 56000 ms error = 0.0000
epoch = 58000 ms error = 0.0000
epoch = 60000 ms error = 0.0000
epoch = 62000 ms error = 0.0000
epoch = 64000 ms error = 0.0000
epoch = 66000 ms error = 0.0000
epoch = 68000 ms error = 0.0000
epoch = 70000 ms error = 0.0000
epoch = 72000 ms error = 0.0000
epoch = 74000 ms error = 0.0000
epoch = 76000 ms error = 0.0000
epoch = 78000 ms error = 0.0000
epoch = 80000 ms error = 0.0000
epoch = 82000 ms error = 0.0000
epoch = 84000 ms error = 0.0000
epoch = 86000 ms error = 0.0000
epoch = 88000 ms error = 0.0000
epoch = 90000 ms error = 0.0000
epoch = 92000 ms error = 0.0000
epoch = 94000 ms error = 0.0000
epoch = 96000 ms error = 0.0000
epoch = 98000 ms error = 0.0000
epoch = 100000 ms error = 0.0000
Training complete

First few data points: actual-predicted:
0: 10.4, 10.4
1: 12.4, 12.399997
2: 10.4, 10.399998
3: 7.24, 7.239999
4: 5.18, 5.179998
5: 5.18, 5.1800036

Accuracy on data (using train data only) = 1.0000


Check fitting and make predictions
10.400000
12.399997
10.399998
7.239999
5.179998
5.180004
8.420000
8.400014
8.009999
7.820001
7.619998
7.030000
8.779999
12.299999
11.899995
7.619998
9.170002
10.299993
9.369985
9.370001
11.005571
9.765030
11.617411
7.548833
Fitting check complete. Last 4 elements are predictions.

Contour data output
4.045813
2.816452
1.824767
1.137846
0.711663
0.371743
0.074409
-0.229591
-0.532858
-0.820935
-1.111734
-1.378032
-1.637107
-1.866647
-2.084059
-2.272927
-2.449593
-2.602150
-2.744790
-2.868440
5.101616
3.928126
2.817924
1.927577
1.378689
0.992474
0.686896
0.384553
0.081674
-0.211306
-0.513871
-0.797549
-1.079718
-1.334598
-1.579788
-1.795226
-1.998267
-2.174294
-2.339072
-2.481772
6.076320
5.005853
3.904143
2.842083
2.111317
1.628387
1.295550
0.992114
0.694255
0.403611
0.097642
-0.195882
-0.494859
-0.771109
-1.042210
-1.284332
-1.515293
-1.717138
-1.906895
-2.071441
6.950460
5.974810
4.965473
3.851760
2.933163
2.290923
1.892880
1.574771
1.281408
0.997926
0.696135
0.401072
0.093773
-0.196840
-0.488519
-0.754338
-1.012167
-1.240364
-1.456721
-1.645210
7.722665
6.845716
5.929287
4.884933
3.859406
3.021070
2.501367
2.138510
1.840916
1.565341
1.272738
0.983109
0.675872
0.379057
0.074333
-0.209644
-0.490755
-0.743879
-0.987057
-1.200842
8.385092
7.636378
6.786125
5.851645
4.846097
3.851687
3.157824
2.699898
2.376406
2.103474
1.821563
1.542006
1.241650
0.946371
0.637004
0.342299
0.044063
-0.230067
-0.498125
-0.737079
8.942748
8.341562
7.564267
6.707480
5.805902
4.770819
3.902169
3.289247
2.899744
2.614655
2.340170
2.072481
1.783492
1.495828
1.189469
0.891974
0.584472
0.295601
0.007213
-0.254597
9.414323
8.946957
8.280718
7.467724
6.667823
5.710054
4.745907
3.947150
3.434529
3.107600
2.829848
2.572357
2.296703
2.020575
1.723004
1.429640
1.120899
0.824904
0.523015
0.243168
9.811937
9.440268
8.908025
8.150397
7.400787
6.563055
5.621483
4.681952
4.000959
3.587431
3.284564
3.030440
2.767048
2.503926
2.218389
1.933890
1.630395
1.334631
1.027209
0.736351
10.175537
9.863550
9.461141
8.807047
8.076820
7.329419
6.497041
5.519481
4.667163
4.110248
3.741848
3.475729
3.220390
2.970493
2.699048
2.426629
2.133133
1.843511
1.537729
1.243029
10.507377
10.223290
9.918739
9.402837
8.711605
7.994077
7.279699
6.377725
5.429671
4.702525
4.213238
3.905226
3.646589
3.407192
3.150025
2.891145
2.610318
2.330766
2.032311
1.740541
10.816490
10.538276
10.294913
9.913773
9.314317
8.598074
7.949271
7.178547
6.249025
5.390554
4.734663
4.337704
4.052529
3.816263
3.571694
3.326669
3.059733
2.792352
2.504740
2.220819
11.108090
10.822721
10.609791
10.332935
9.863728
9.176229
8.533703
7.872141
7.052913
6.157584
5.341790
4.803967
4.451927
4.202708
3.965702
3.733673
3.480984
3.226665
2.951602
2.678354
11.384515
11.086568
10.881529
10.672359
10.332970
9.733843
9.076634
8.459555
7.774402
6.944459
6.041051
5.341776
4.869237
4.576705
4.335547
4.113518
3.874666
3.633699
3.371824
3.110466
11.659449
11.349134
11.136170
10.964602
10.731761
10.271783
9.635222
9.004146
8.413489
7.717496
6.832662
6.008774
5.366727
4.978125
4.706646
4.486829
4.260540
4.033522
3.785746
3.537268
11.917098
11.600225
11.369978
11.210281
11.046474
10.726101
10.178593
9.520733
8.950395
8.378374
7.607353
6.754374
5.960260
5.423176
5.075565
4.838966
4.619288
4.405175
4.171576
3.936073
12.098344
11.781948
11.536549
11.373545
11.240405
11.004770
10.556338
9.907302
9.314929
8.795834
8.134595
7.326676
6.469179
5.810926
5.368248
5.096452
4.872959
4.666386
4.443198
4.217548
12.323530
12.015126
11.751193
11.572577
11.458839
11.302968
10.990881
10.418719
9.786265
9.276517
8.734221
8.050215
7.195324
6.416559
5.812407
5.449058
5.197269
4.993474
4.782648
4.570236
12.530005
12.236482
11.959990
11.758087
11.645442
11.536526
11.334396
10.894496
10.263940
9.714354
9.224235
8.676029
7.915901
7.099167
6.350034
5.844961
5.520727
5.301595
5.097754
4.897969
12.718585
12.444228
12.163688
11.936205
11.811431
11.725037
11.597488
11.296412
10.743083
10.148525
9.644846
9.185499
8.568315
7.801858
6.978507
6.323596
5.872056
5.602791
5.392229
5.201913
Contour fitting complete.

End model


C:\Users\yzhu2\evaptransmission>



































































































































































